{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import ncecessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler      # For data standardization scaling \n",
    "from sklearn.model_selection import train_test_split  # For train_testing_data_split\n",
    "import joblib                                         # To load KNN, RF, XGBoost, and SVR models \n",
    "from keras.models import load_model                   # To load ANN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read training data\n",
    "    \n",
    "Download the 'IJHMT_MeatFoam_Data.csv' file from GitHub repository. Need to put the file in the directory or you need to put the data directory information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('IJHMT_MeatFoam_Data.csv') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define feature, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[['PPI','Porosity','Re','Dh']]                 # Input features\n",
    "y = df[['f','Nu']]                                   # Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split data into training and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_before_scaling, x_test_before_scaling, y_train, y_test = train_test_split(x, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# For this paper, test data set are 25% of the total data. You can choose other % as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_scaled = scaler.fit_transform(x_train_before_scaling)\n",
    "x_test_scaled = scaler.transform(x_test_before_scaling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import New data\n",
    "For explanatory purposes, we have provided 'porosity_data.csv' file in the GitHub repository (we have used this data in the paper). You can have your own data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.read_csv('porosity_data.csv')            # Read your data file (.csv file). Need to put the file in the directory or you need to put the directory information\n",
    "new_data_before_scaling = new_data[['PPI','Porosity','Re','Dh']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply scaling on new data data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_scaled = scaler.transform(new_data_before_scaling)\n",
    "input_data = pd.DataFrame(new_data_scaled,columns = ['PPI', 'Porosity', 'Re', 'Dh'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load all models\n",
    "\n",
    "Download all '.joblib' and '.h5' file from the GitHub repository and put them in the directory. Please note that '.h5' file contains both the ANN model architecture and corresponding weights and biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = joblib.load(\"KNN_model.joblib\")\n",
    "RF = joblib.load(\"RF_model.joblib\")\n",
    "XGB = joblib.load(\"XGB_model.joblib\")\n",
    "SVR = joblib.load(\"SVR_model.joblib\")\n",
    "ANN = load_model('ANN_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict using ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_prediction = KNN.predict(input_data)\n",
    "RF_prediction = RF.predict(input_data)\n",
    "XGB_prediction = XGB.predict(input_data)\n",
    "SVR_prediction = SVR.predict(input_data)\n",
    "ANN_prediction = ANN.predict(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract results of Friction factor, f and Nusselt number, Nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediced_f_KNN = KNN_prediction[:,0]\n",
    "Prediced_f_RF = RF_prediction[:,0]\n",
    "Prediced_f_XGB = XGB_prediction[:,0]\n",
    "Prediced_f_SVR = SVR_prediction[:,0]\n",
    "Prediced_f_ANN = ANN_prediction[:,0]\n",
    "\n",
    "Prediced_Nu_KNN = KNN_prediction[:,1]\n",
    "Prediced_Nu_RF = RF_prediction[:,1]\n",
    "Prediced_Nu_XGB = XGB_prediction[:,1]\n",
    "Prediced_Nu_SVR = SVR_prediction[:,1]\n",
    "Prediced_Nu_ANN = ANN_prediction[:,1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
